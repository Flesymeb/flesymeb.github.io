<!doctype html><html lang=zh-cn dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="zh-cn"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>使用 LLaMAFactory 实现大模型微调 &#183; Blog</title>
<meta name=title content="使用 LLaMAFactory 实现大模型微调 &#183; Blog"><meta name=description content="A simple blog."><meta name=keywords content="Study,LLM,"><link rel=canonical href=https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/><link type=text/css rel=stylesheet href=/css/main.bundle.min.18b3ce5d415e4be4178771f659bad704c60917c9823a666f8d122170718f3f377973fe317af18a3762afa9147aef06b90b2b332fe5b0f665f54b7aef6d8014e4.css integrity="sha512-GLPOXUFeS+QXh3H2WbrXBMYJF8mCOmZvjRIhcHGPPzd5c/4xevGKN2KvqRR67wa5CyszL+Ww9mX1S3rvbYAU5A=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/"><meta property="og:site_name" content="Blog"><meta property="og:title" content="使用 LLaMAFactory 实现大模型微调"><meta property="og:description" content=" 本文主要介绍如何使用 LLaMAFactory 实现大模型微调，基于 Qwen2.5-7B-Instruct 模型进行 LoRA 微调
基础概念 # 大模型训练流程 # ChatGPT 的训练流程 图中的 Reward Modeling 和 Reinforcement Learning 可以看做一步，即 RLHF，因此训练一个大模型一般可以分为三步："><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-02-19T19:14:32+08:00"><meta property="article:modified_time" content="2025-02-19T19:14:32+08:00"><meta property="article:tag" content="Study"><meta property="article:tag" content="LLM"><meta property="og:image" content="https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/featured.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/featured.png"><meta name=twitter:title content="使用 LLaMAFactory 实现大模型微调"><meta name=twitter:description content=" 本文主要介绍如何使用 LLaMAFactory 实现大模型微调，基于 Qwen2.5-7B-Instruct 模型进行 LoRA 微调
基础概念 # 大模型训练流程 # ChatGPT 的训练流程 图中的 Reward Modeling 和 Reinforcement Learning 可以看做一步，即 RLHF，因此训练一个大模型一般可以分为三步："><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"文档","name":"使用 LLaMAFactory 实现大模型微调","headline":"使用 LLaMAFactory 实现大模型微调","abstract":"\u003cblockquote\u003e\n\u003cp\u003e本文主要介绍如何使用 LLaMAFactory 实现大模型微调，基于 Qwen2.5-7B-Instruct 模型进行 LoRA 微调\u003c\/p\u003e\n\u003c\/blockquote\u003e\n\n\n\u003ch1 class=\u0022relative group\u0022\u003e基础概念 \n    \u003cdiv id=\u0022%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5\u0022 aria-label=\u0022锚点\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h1\u003e\n\n\n\u003ch2 class=\u0022relative group\u0022\u003e大模型训练流程 \n    \u003cdiv id=\u0022%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B\u0022 aria-label=\u0022锚点\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h2\u003e\n\u003cp\u003e\u003cstrong\u003eChatGPT 的训练流程\u003c\/strong\u003e\n\n    \u003cfigure\u003e\n      \u003cimg\n        class=\u0022my-0 rounded-md\u0022\n        loading=\u0022lazy\u0022\n        srcset=\u0022\n        \/docs\/study\/20250219_qwen_fine_tune\/imgs\/01_hu7432936583427614731.png 330w,\n        \/docs\/study\/20250219_qwen_fine_tune\/imgs\/01_hu6483044369201846705.png 660w,\n        \/docs\/study\/20250219_qwen_fine_tune\/imgs\/01_hu10302658420192218926.png 1024w,\n        \/docs\/study\/20250219_qwen_fine_tune\/imgs\/01_hu5206765031144962701.png 2x\u0022\n        src=\u0022\/docs\/study\/20250219_qwen_fine_tune\/imgs\/01_hu6483044369201846705.png\u0022\n        alt=\u0022\u0022\n      \/\u003e\n      \n    \u003c\/figure\u003e\n\n图中的 Reward Modeling 和 Reinforcement Learning 可以看做一步，即 RLHF，因此训练一个大模型一般可以分为三步：\u003c\/p\u003e","inLanguage":"zh-cn","url":"https:\/\/flesymeb.github.io\/docs\/study\/20250219_qwen_fine_tune\/","author":{"@type":"Person","name":"Hyoung Yan"},"copyrightYear":"2025","dateCreated":"2025-02-19T19:14:32\u002b08:00","datePublished":"2025-02-19T19:14:32\u002b08:00","dateModified":"2025-02-19T19:14:32\u002b08:00","keywords":["Study","LLM"],"mainEntityOfPage":"true","wordCount":"7000"}]</script><meta name=author content="Hyoung Yan"><link href=https://github.com/flesymeb/ rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyC2QtnNcwjWp_givX90bPrhi4d1qD7CmNk",authDomain:"AIzaSyC2QtnNcwjWp_givX90bPrhi4d1qD7CmNk",projectId:"yzlevol-blog",storageBucket:"yzlevol-blog.appspot.com",messagingSenderId:"470650854099",appId:"1:470650854099:web:da89bf5240e1dee9d7d226",measurementId:"G-W5W0HTZVH2"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>跳过正文</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div><a href=/ class=flex><span class=sr-only>Blog</span>
<img src=/img/MyImgs/180x180.png width=65 height=65 class="logo max-h-[5rem] max-w-[5rem] object-scale-down object-left nozoom" alt=Blog></a></div><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Blog</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/docs/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>文档</p></a><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>帖子</p></a><a href=/tabs/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>导航</p></a><a href=/media/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>影音</p></a><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>标签</p></a><a href=https://github.com/flesymeb/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/docs/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>文档</p></a></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>帖子</p></a></li><li class=mt-1><a href=/tabs/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>导航</p></a></li><li class=mt-1><a href=/media/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>影音</p></a></li><li class=mt-1><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>标签</p></a></li><li class=mt-1><a href=https://github.com/flesymeb/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div><script>(function(){var e=$(".main-menu"),t=window.location.pathname;e.find('a[href="'+t+'"]').each(function(e,t){$(t).children("p").addClass("active")})})()</script></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/docs/study/20250219_qwen_fine_tune/featured_hu2193678247247219511.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/>.</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/docs/>文档</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/docs/study/20250219_qwen_fine_tune/>使用 LLaMAFactory 实现大模型微调</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">使用 LLaMAFactory 实现大模型微调</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-02-19T19:14:32+08:00>2025-02-19</time><span class="px-2 text-primary-500">&#183;</span><span>7000 字</span><span class="px-2 text-primary-500">&#183;</span><span title=预计阅读>14 分钟</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_docs/Study/20250219_Qwen_Fine_Tune/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span>
<span class=mb-[2px]><a href=https://github.com/flesymeb/flesymebBlog/tree/main/content/docs/Study/20250219_Qwen_Fine_Tune/index.md class="text-lg hover:text-primary-500" rel="noopener noreferrer" target=_blank title=编辑内容><span class="inline-block align-text-bottom"><span class="relative block icon"><svg height="1em" viewBox="0 0 512 512"><path fill="currentcolor" d="M441 58.9 453.1 71c9.4 9.4 9.4 24.6.0 33.9L424 134.1 377.9 88 407 58.9c9.4-9.4 24.6-9.4 33.9.0zM209.8 256.2 344 121.9 390.1 168 255.8 302.2c-2.9 2.9-6.5 5-10.4 6.1L186.9 325l16.7-58.5c1.1-3.9 3.2-7.5 6.1-10.4zM373.1 25 175.8 222.2c-8.7 8.7-15 19.4-18.3 31.1l-28.6 1e2c-2.4 8.4-.1 17.4 6.1 23.6s15.2 8.5 23.6 6.1l1e2-28.6c11.8-3.4 22.5-9.7 31.1-18.3L487 138.9c28.1-28.1 28.1-73.7.0-101.8L474.9 25C446.8-3.1 401.2-3.1 373.1 25zM88 64C39.4 64 0 103.4.0 152V424c0 48.6 39.4 88 88 88H360c48.6.0 88-39.4 88-88V312c0-13.3-10.7-24-24-24s-24 10.7-24 24V424c0 22.1-17.9 40-40 40H88c-22.1.0-40-17.9-40-40V152c0-22.1 17.9-40 40-40H2e2c13.3.0 24-10.7 24-24s-10.7-24-24-24H88z"/></svg>
</span></span></a></span><span class="px-2 text-primary-500">&#183;</span>
<script type=text/javascript src=/js/zen-mode.min.63c8a202661f4a2063fdc2706685d668e8ea3da613da2224e9da527e5876e4f53dcac39ab60732626fb4151feae5d430d0cf44731e5d3c726522fcc1519c1547.js integrity="sha512-Y8iiAmYfSiBj/cJwZoXWaOjqPaYT2iIk6dpSflh25PU9ysOatgcyYm+0FR/q5dQw0M9Ecx5dPHJlIvzBUZwVRw=="></script><span class=mb-[2px]><span id=zen-mode-button class="text-lg hover:text-primary-500" title data-title-i18n-disable data-title-i18n-enable><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 50 50" width="50" height="50"><path fill="currentcolor" d="M12.980469 4C9.1204688 4 5.9804688 7.14 5.9804688 11L6 26H9.9804688V11c0-1.65 1.3400002-3 3.0000002-3H40.019531c1.66.0 3 1.35 3 3V39c0 1.65-1.34 3-3 3H29c0 1.54-.579062 2.94-1.539062 4H40.019531c3.86.0 7-3.14 7-7V11c0-3.86-3.14-7-7-7H12.980469zM7 28c-2.206.0-4 1.794-4 4V42c0 2.206 1.794 4 4 4H23c2.206.0 4-1.794 4-4V32c0-2.206-1.794-4-4-4H7zm0 4H23L23.001953 42H7V32z"/></svg></span></span></span></span></div><div class="flex flex-row flex-wrap items-center"></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/tags/study/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Study
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/tags/llm/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">LLM</span></span></span></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">目录</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#大模型训练流程>大模型训练流程</a></li><li><a href=#模型名称各部分释义>模型名称各部分释义</a></li><li><a href=#微调sft>微调（SFT）</a><ul><li><a href=#微调方法分类>微调方法分类</a></li><li><a href=#训练框架选择>训练框架选择</a></li></ul></li></ul><ul><li><a href=#数据集格式>数据集格式</a><ul><li><a href=#alpaca-格式>ALpaca 格式</a><ul><li><a href=#指令监督微调数据集><strong>指令监督微调数据集</strong></a></li><li><a href=#预训练数据集>预训练数据集</a></li><li><a href=#偏好数据集>偏好数据集</a></li><li><a href=#kto-数据集>KTO 数据集</a></li><li><a href=#多模态数据集>多模态数据集</a></li></ul></li><li><a href=#sharegpt-格式>Sharegpt 格式</a><ul><li><a href=#指令监督微调数据集-1>指令监督微调数据集</a></li><li><a href=#偏好数据集-1>偏好数据集</a></li><li><a href=#openai-格式>OpenAI 格式</a></li></ul></li></ul></li><li><a href=#sft-超参数调整>SFT 超参数调整：</a></li><li><a href=#rlhf>RLHF</a></li><li><a href=#dpo>DPO</a></li><li><a href=#如何训练垂直领域大模型>如何训练垂直领域大模型</a></li></ul><ul><li><a href=#结果查看>结果查看</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">目录</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#大模型训练流程>大模型训练流程</a></li><li><a href=#模型名称各部分释义>模型名称各部分释义</a></li><li><a href=#微调sft>微调（SFT）</a><ul><li><a href=#微调方法分类>微调方法分类</a></li><li><a href=#训练框架选择>训练框架选择</a></li></ul></li></ul><ul><li><a href=#数据集格式>数据集格式</a><ul><li><a href=#alpaca-格式>ALpaca 格式</a><ul><li><a href=#指令监督微调数据集><strong>指令监督微调数据集</strong></a></li><li><a href=#预训练数据集>预训练数据集</a></li><li><a href=#偏好数据集>偏好数据集</a></li><li><a href=#kto-数据集>KTO 数据集</a></li><li><a href=#多模态数据集>多模态数据集</a></li></ul></li><li><a href=#sharegpt-格式>Sharegpt 格式</a><ul><li><a href=#指令监督微调数据集-1>指令监督微调数据集</a></li><li><a href=#偏好数据集-1>偏好数据集</a></li><li><a href=#openai-格式>OpenAI 格式</a></li></ul></li></ul></li><li><a href=#sft-超参数调整>SFT 超参数调整：</a></li><li><a href=#rlhf>RLHF</a></li><li><a href=#dpo>DPO</a></li><li><a href=#如何训练垂直领域大模型>如何训练垂直领域大模型</a></li></ul><ul><li><a href=#结果查看>结果查看</a></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})(),function(){var t,e=$("#TableOfContents");if(e.length>0){t=$(window);function n(){var s,o=t.scrollTop(),i=$(".anchor"),n="";if(i.each(function(e,t){t=$(t),t.offset().top-$(window).height()/3<=o&&(n=decodeURIComponent(t.attr("id")))}),s=e.find("a.active"),s.length==1&&s.eq(0).attr("href")=="#"+n)return!0;s.each(function(e,t){$(t).removeClass("active")}),e.find('a[href="#'+n+'"]').addClass("active"),e.find('a[href="#'+n+'"]').parentsUntil("#TableOfContents").each(function(e,t){$(t).children("a").parents("ul").show()})}t.on("scroll",n),$(document).ready(function(){n()})}}()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><blockquote><p>本文主要介绍如何使用 LLaMAFactory 实现大模型微调，基于 Qwen2.5-7B-Instruct 模型进行 LoRA 微调</p></blockquote><h1 class="relative group">基础概念<div id=%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5 aria-label=锚点>#</a></span></h1><h2 class="relative group">大模型训练流程<div id=%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B aria-label=锚点>#</a></span></h2><p><strong>ChatGPT 的训练流程</strong><figure><img class="my-0 rounded-md" loading=lazy srcset="/docs/study/20250219_qwen_fine_tune/imgs/01_hu7432936583427614731.png 330w,
/docs/study/20250219_qwen_fine_tune/imgs/01_hu6483044369201846705.png 660w,
/docs/study/20250219_qwen_fine_tune/imgs/01_hu10302658420192218926.png 1024w,
/docs/study/20250219_qwen_fine_tune/imgs/01_hu5206765031144962701.png 2x" src=/docs/study/20250219_qwen_fine_tune/imgs/01_hu6483044369201846705.png alt></figure>图中的 Reward Modeling 和 Reinforcement Learning 可以看做一步，即 RLHF，因此训练一个大模型一般可以分为三步：</p><ol><li><strong>预训练（Pre Training，PT）</strong>：这一阶段是模型训练的基础，利用海量数据、大量算力通过无监督训练得到一个基础模型。预训练后的模型具备强大的语言生成能力，但由于它主要是无监督训练的结果，可能不会直接适应具体的任务（如问答、对话），需要进一步的微调。</li><li><strong>监督微调（Supervised Fine-Tuning，SFT）</strong>：这一阶段则是对 Base 模型进行微调，让模型能够适用特定任务，最终得到一个 SFT 模型。<ul><li>微调的目的是让模型更好地理解特定任务的需求。例如，通过使用对话数据集对模型进行微调，可以让模型在遇到问题时生成更相关的答案，而不是简单地生成与问题相似的文本。</li><li>这些问答对话由人类准备的，通常是有标签的，包含了问题和答案对，或者其他特定任务的数据。</li></ul></li><li><strong>强化学习（Reinforcement Learning form Human Feedback，RLHF）</strong>：这一阶段通过引入人类反馈（或者基于人类反馈训练的奖励模型）进一步优化模型的生成质量，使其生成的回答更符合用户的期望和人类的价值观。<ul><li>一般按照 3H 原则进行打分：<ul><li>Helpful：判断模型遵循用户指令以及推断指令的能力。</li><li>Honest：判断模型产生幻觉(编造事实)的倾向。</li><li>Harmless：判断模型的输出是否适当、是否诋毁或包含贬义内容。</li></ul></li><li>由于直接从人类获取反馈的成本较高，通常会先训练一个奖励模型（Reward Model，RM）来代替人类打分，这样可以在 RL 的框架下进行大规模的自动优化。</li></ul></li></ol><p>预训练由于对算力和数据需求都比较大，因此一般玩家不会涉及到预训练，更多的是基于开源的基础模型（LLama、deepseek、Qwen、ChatGLM…）做微调、强化学习以满足自身需求。</p><h2 class="relative group">模型名称各部分释义<div id=%E6%A8%A1%E5%9E%8B%E5%90%8D%E7%A7%B0%E5%90%84%E9%83%A8%E5%88%86%E9%87%8A%E4%B9%89 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%A8%A1%E5%9E%8B%E5%90%8D%E7%A7%B0%E5%90%84%E9%83%A8%E5%88%86%E9%87%8A%E4%B9%89 aria-label=锚点>#</a></span></h2><p>以 Qwen1.5-14B-Chat-GQPT-Int4 为例，可以分为 5 个部分，具体含义如下图：<figure><img class="my-0 rounded-md" loading=lazy srcset="/docs/study/20250219_qwen_fine_tune/image/index/1739967632276_hu8427250436510392647.png 330w,
/docs/study/20250219_qwen_fine_tune/image/index/1739967632276_hu8277796915611372224.png 660w,
/docs/study/20250219_qwen_fine_tune/image/index/1739967632276_hu10103005619937586218.png 1024w,
/docs/study/20250219_qwen_fine_tune/image/index/1739967632276_hu17800990908518897489.png 2x" src=/docs/study/20250219_qwen_fine_tune/image/index/1739967632276_hu8277796915611372224.png alt=1739967632276></figure></p><p>5 个参数含义如下：</p><ul><li><strong>模型系列</strong>：一般一个公司、组织的模型都会归属于同一个系列，比如阿里的 Qwen 系列、Meta 的 Llama 系列，智普的 Chatglm 系列。</li><li><strong>模型版本</strong>：一个系列的模型也会有多个版本，一般是有大更新时才会更新，比如 Qwen 系列就存在 Qwen、Qwen1.5、Qwen2.5 系列。</li><li><strong>参数量</strong>：一般为 xx B，B 为单位，表示 10 亿参数，比如 7B 则是有 70 亿参数，72B 则是 720 亿参数。这个只是一个大致范围，比如 68 亿、72 亿参数的模型一般也叫做 7B。</li><li><strong>微调</strong>：开源模型为了能够直接使用，一般会提供经过问答任务微调的版本，即 Chat 模型。</li><li><strong>量化</strong>：为了降低内存占用有的也会提供量化版本，比如大模型一般使用 FP32/FP16 精度，即一个参数占 4 或者 2 字节，而量化则是将权重参数使用更低精度的格式来存放，比如量化为 FP8 则是只需要 1 字节，Int4 则只需要 4 位。</li></ul><p><strong>其中需要注意的就是是否经过微调、量化：</strong></p><ul><li><strong>基础模型</strong>：不带任意后缀，或者 -Base 后缀，就是预训练后未经过微调的原始模型，比如 Qwen1.5、Llama3。</li><li><strong>SFT 模型</strong>：带特定领域任务后缀，比如 xxx-chat，就是对基础模型做了问答任务微调，比如 Qwen1.5-Chat、Baichuan2-Chat。</li><li><strong>量化模型</strong>：它通过将模型中的高精度浮点数参数转换为低精度的整数参数来减少模型的存储和计算需求。这样做可以显著降低模型的内存占用，加快推理速度，并减少能耗。量化可以带来显著的效率提升，但也可能引入一些精度损失。<ul><li><strong>GGUF</strong>：GGUF（以前称为 GGML）是一种量化方法，允许用户使用 CPU 来运行 LLM，但也可以将其某些层加载到 GPU 以提高速度。</li><li><strong>GPTQ</strong>：GPTQ 是一种 4 位量化的训练后量化（PTQ）方法，主要关注 GPU 推理和性能。</li><li><strong>AWQ</strong>：是一种新格式（激活感知权重量化），它是一种类似于 GPTQ 的量化方法。AWQ 和 GPTQ 作为方法有几个不同之处，但最重要的是 AWQ 假设并非所有权重对 LLM 的性能都同等重要。也就是说在量化过程中会跳过一小部分权重，这有助于减轻量化损失。所以他们的论文提到了与 GPTQ 相比的可以由显著加速，同时保持了相似的，有时甚至更好的性能。</li></ul></li></ul><h2 class="relative group">微调（SFT）<div id=%E5%BE%AE%E8%B0%83sft class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%BE%AE%E8%B0%83sft aria-label=锚点>#</a></span></h2><p>大模型微调，通常指有监督微调（Supervised Fine-Tuning, SFT），是在预训练模型（一般称为“基座模型”）的基础上进行的训练过程。</p><p>预训练模型通常已经掌握了广泛的语言知识和语义表示，但为了让模型在特定任务或领域上表现得更好，我们会在特定任务的数据集上对其进行微调。它在任务性能、领域适应性、数据利用效率和计算成本等方面具有显著的优势。</p><h3 class="relative group">微调方法分类<div id=%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95%E5%88%86%E7%B1%BB class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95%E5%88%86%E7%B1%BB aria-label=锚点>#</a></span></h3><p>微调根据更新参数量的不同可以分为以下两种：</p><ul><li><strong>全量参数更新 Full Fine-tuning（FFT）</strong>：即对预训练模型的所有参数进行更新，训练速度较慢，消耗机器资源较多。</li><li><strong>参数高效微调 Parameter-Efficient Fine-Tuning（PEFT）</strong>：只对部分参数做调整，训练速度快，消耗机器资源少。</li></ul><blockquote><p>理论上，预训练和微调都可以做全量参数更新和部分参数更新，但是一般实际训练时都是 <strong>预训练 + 全量</strong>，<strong>微调 + 部分参数更新</strong> 这样组合的。</p></blockquote><p>FFT 的原理，就是用特定的数据，对大模型进行训练，将 W 变成 W′，W′相比 W，最大的优点就是上述特定数据领域的表现会好很多。但是可能造成训练的成本比较高和灾难性遗忘（Catastrophic Forgetting），在其他领域的能力变差。</p><p>PEFT 主要想解决的问题就是 FFT 存在的两个问题，也是目前比较主流的微调方案。</p><p><strong>PERT 可分为三类：</strong></p><ul><li><strong>添加额外参数的 Addition-based（A）</strong><ul><li>类似适配器的方法（Adapter-like methods）</li><li>软提示（Soft prompts）</li></ul></li><li><strong>选取部分参数更新 Selection-based（S）</strong></li><li><strong>引入重参数化 Reparametrization-based（R）</strong><figure><img class="my-0 rounded-md" loading=lazy srcset="/docs/study/20250219_qwen_fine_tune/image/index/1739968559817_hu3953722620791358092.png 330w,
/docs/study/20250219_qwen_fine_tune/image/index/1739968559817_hu8139968671336125205.png 660w,
/docs/study/20250219_qwen_fine_tune/image/index/1739968559817_hu15666841102350509114.png 1024w,
/docs/study/20250219_qwen_fine_tune/image/index/1739968559817_hu6221184781074052269.png 2x" src=/docs/study/20250219_qwen_fine_tune/image/index/1739968559817_hu8139968671336125205.png alt=1739968559817></figure></li></ul><p>常见的 PEFT 方法：BitFit、Prompt Tuning、Prefix Tuning、P-Tuning、P-Tuning V2、Adapter Tuning、LoRA、QLoRA、MAM Adapter、UniPELT、 Freeze tuning 等等<figure><img class="my-0 rounded-md" loading=lazy srcset="/docs/study/20250219_qwen_fine_tune/image/index/1739968607628_hu17664982846914347019.png 330w,
/docs/study/20250219_qwen_fine_tune/image/index/1739968607628_hu9277605059925760785.png 660w,
/docs/study/20250219_qwen_fine_tune/image/index/1739968607628_hu7029719827667769265.png 1024w,
/docs/study/20250219_qwen_fine_tune/image/index/1739968607628_hu16093976592995419447.png 2x" src=/docs/study/20250219_qwen_fine_tune/image/index/1739968607628_hu9277605059925760785.png alt=1739968607628></figure></p><ul><li><strong>BitFit</strong> : 只更新模型中的 bias 参数或部分 bias 参数。</li><li><strong>Prefix Tuning</strong> : 在模型输入前添加可训练的前缀向量。</li><li><strong>Prompt Tuning</strong> : 在输入层加入提示词（prompt tokens）进行微调。</li><li><strong>P-Tuning</strong> : 在模型的每层都加入可学习的提示词。</li><li><strong>Adapter Tuning</strong> : 在 Transformer 的每一层插入小型的适配器网络。</li><li><strong>LoRA (Low-Rank Adaptation)</strong>: 通过在模型的权重矩阵中引入低秩结构来进行微调。</li><li><strong>QLoRA(Quantized LoRA)</strong>：提出了 NormalFloat 数据类型, 通过量化降低基座模型的显存占用，使得 65B 模型在单 GPU 上可以完成训练。</li></ul><h3 class="relative group">训练框架选择<div id=%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9 aria-label=锚点>#</a></span></h3><p>比较主流的几个微调工具：</p><ul><li><strong>huggingface/transformers</strong>：最基础的一个库，提供了丰富的预训练模型和微调工具，支持大多数主流的 NLP 任务（如文本分类、序列标注、生成任务等）。适合进行快速实验和生产部署，有着广泛的社区支持。</li><li><strong>huggingface/peft</strong>：Parameter-Efficient Fine-Tuning，huggingface 开源的微调基础工具。</li><li><strong>modelscope/ms-swift</strong>：modelscope 开源的轻量级微调框架，以中文大模型为主，支持各类微调方法。可以通过执行脚本进行微调，也可以在代码环境中一键微调。自带微调数据集和验证数据集，可以一键微调和模型验证。</li><li><strong>hiyouga/LLaMA-Factory</strong>：全栈微调工具，支持海量模型和各种主流微调方法。支持运行脚本微调和基于 Web 端微调，自带基础训练数据集。除微调外，还支持增量预训练和全量微调。</li><li><strong>NVIDIA/Megatron-LM</strong>：NVIDIA 开发的大模型训练框架，支持大规模的预训练和微调。适用于需要极高性能和规模的大模型训练和微调。</li></ul><p>快速实验选择 Transformers 即可，超大规模的选择 NVIDIA/Megatron-LM，普通规模就选择使用较为简单的 hiyouga/LLaMA-Factory。</p><h1 class="relative group">SFT 微调准备<div id=sft-%E5%BE%AE%E8%B0%83%E5%87%86%E5%A4%87 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#sft-%E5%BE%AE%E8%B0%83%E5%87%86%E5%A4%87 aria-label=锚点>#</a></span></h1><blockquote><p>数据集的质量对模型微调至关重要，<strong>微调后模型效果 80%取决于 SFT 训练数据</strong>，少量高质数据要比大量低质或者普通的数据好很多。</p></blockquote><h2 class="relative group">数据集格式<div id=%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%BC%E5%BC%8F class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%BC%E5%BC%8F aria-label=锚点>#</a></span></h2><p>通常 1 万条左右的精标数据即可发挥良好的效果，在扩充数据规模时需要注意数据多样性，多样性的数据可以提高模型性能。
数据质量可以通过 ppl、reward model，文本质量分类模型等方式进行初步评估。经过人工进行后续筛选。</p><h3 class="relative group">ALpaca 格式<div id=alpaca-%E6%A0%BC%E5%BC%8F class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#alpaca-%E6%A0%BC%E5%BC%8F aria-label=锚点>#</a></span></h3><h4 class="relative group"><strong>指令监督微调数据集</strong><div id=%E6%8C%87%E4%BB%A4%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%E9%9B%86 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%8C%87%E4%BB%A4%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%E9%9B%86 aria-label=锚点>#</a></span></h4><p>指令监督微调（Instuct Tuning）通过让模型学习详细的指令以及对应的回答来优化模型在特定指令下的表现。
<code>instruction</code> 列对应的内容会与 <code>input</code> 列对应的内容拼接后作为人类指令，即人类指令为 <code>instruction\ninput</code>，而 <code>output</code> 列对应的内容为模型回答。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=s2>&#34;alpaca_zh_demo.json&#34;</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;计算这些物品的总费用。 &#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;input&#34;</span>      <span class=p>:</span> <span class=s2>&#34;输入：汽车 - $3000，衣服 - $100，书 - $20。&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;output&#34;</span>     <span class=p>:</span> <span class=s2>&#34;汽车、衣服和书的总费用为 $3000 + $100 + $20 = $3120。&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span><span class=err>,</span>
</span></span></code></pre></div><p>在上例中，人类的最终输入是：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-plaintext data-lang=plaintext><span class=line><span class=cl>计算这些物品的总费用。
</span></span><span class=line><span class=cl>输入：汽车 - $3000，衣服 - $100，书 - $20。
</span></span></code></pre></div><p>模型的回答：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-plaintext data-lang=plaintext><span class=line><span class=cl>汽车、衣服和书的总费用为 $3000 + $100 + $20 = $3120。
</span></span></code></pre></div><p>如果指定，<code>system</code> 列对应的内容将被作为系统提示词。</p><p><code>history</code> 列是由多个字符串二元组构成的列表，分别代表历史消息中每轮对话的指令和回答。注意在指令监督微调时，历史消息中的回答内容也会被用于模型学习。
下面提供一个 <code>alpaca</code> 格式 多轮 对话的例子，对于单轮对话只需省略 <code>history</code> 列即可。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>[</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;今天的天气怎么样？&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;input&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;output&#34;</span><span class=p>:</span> <span class=s2>&#34;今天的天气不错，是晴天。&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;history&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;今天会下雨吗？&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;今天不会下雨，是个好天气。&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>],</span>
</span></span><span class=line><span class=cl>      <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;今天适合出去玩吗？&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;非常适合，空气质量很好。&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span></code></pre></div><h4 class="relative group">预训练数据集<div id=%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86 aria-label=锚点>#</a></span></h4><p>大语言模型通过学习未被标记的文本进行预训练，从而学习语言的表征。通常，预训练数据集从互联网上获得，因为互联网上提供了大量的不同领域的文本信息，有助于提升模型的泛化能力。 预训练数据集文本描述格式如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>[</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;document&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;document&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span></code></pre></div><h4 class="relative group">偏好数据集<div id=%E5%81%8F%E5%A5%BD%E6%95%B0%E6%8D%AE%E9%9B%86 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%81%8F%E5%A5%BD%E6%95%B0%E6%8D%AE%E9%9B%86 aria-label=锚点>#</a></span></h4><p>偏好数据集用于奖励模型训练、DPO 训练和 ORPO 训练。对于系统指令和人类输入，偏好数据集给出了一个更优的回答和一个更差的回答。</p><p>一些研究 表明通过让模型学习“什么更好”可以使得模型更加迎合人类的需求。 甚至可以使得参数相对较少的模型的表现优于参数更多的模型。</p><p>偏好数据集需要在 chosen 列中提供更优的回答，并在 rejected 列中提供更差的回答，在一轮问答中其格式如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>[</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;人类指令（必填）&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;input&#34;</span><span class=p>:</span> <span class=s2>&#34;人类输入（选填）&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;chosen&#34;</span><span class=p>:</span> <span class=s2>&#34;优质回答（必填）&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;rejected&#34;</span><span class=p>:</span> <span class=s2>&#34;劣质回答（必填）&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span></code></pre></div><h4 class="relative group">KTO 数据集<div id=kto-%E6%95%B0%E6%8D%AE%E9%9B%86 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#kto-%E6%95%B0%E6%8D%AE%E9%9B%86 aria-label=锚点>#</a></span></h4><p>KTO 数据集与偏好数据集类似，但不同于给出一个更优的回答和一个更差的回答，KTO 数据集对每一轮问答只给出一个 <code>true</code>/<code>false</code> 的 <code>label</code>。 除了 <code>instruction</code> 以及 <code>input</code> 组成的人类最终输入和模型回答 <code>output</code> ，KTO 数据集还需要额外添加一个 <code>kto_tag</code> 列（true/false）来表示人类的反馈。</p><h4 class="relative group">多模态数据集<div id=%E5%A4%9A%E6%A8%A1%E6%80%81%E6%95%B0%E6%8D%AE%E9%9B%86 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%95%B0%E6%8D%AE%E9%9B%86 aria-label=锚点>#</a></span></h4><p>多模态数据集需要额外添加一个 images 列，包含输入图像的路径。目前我们仅支持单张图像输入。</p><h3 class="relative group">Sharegpt 格式<div id=sharegpt-%E6%A0%BC%E5%BC%8F class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#sharegpt-%E6%A0%BC%E5%BC%8F aria-label=锚点>#</a></span></h3><blockquote><p>ShareGPT 格式中的 KTO 数据集(样例)和多模态数据集(样例) 与 Alpaca 格式的类似。
预训练数据集不支持 ShareGPT 格式。</p></blockquote><h4 class="relative group">指令监督微调数据集<div id=%E6%8C%87%E4%BB%A4%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%E9%9B%86-1 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%8C%87%E4%BB%A4%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%E9%9B%86-1 aria-label=锚点>#</a></span></h4><p>相比 alpaca 格式的数据集， sharegpt 格式支持 <strong>更多</strong> 的角色种类，例如 human、gpt、observation、function 等等。它们构成一个对象列表呈现在 conversations 列中。 下面是 sharegpt 格式的一个例子：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;conversations&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;human&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;你好，我出生于1990年5月15日。你能告诉我我今天几岁了吗？&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;function_call&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;{\&#34;name\&#34;: \&#34;calculate_age\&#34;, \&#34;arguments\&#34;: {\&#34;birthdate\&#34;: \&#34;1990-05-15\&#34;}}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;observation&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;{\&#34;age\&#34;: 31}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;gpt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;根据我的计算，你今天31岁了。&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;tools&#34;</span><span class=p>:</span> <span class=s2>&#34;[{\&#34;name\&#34;: \&#34;calculate_age\&#34;, \&#34;description\&#34;: \&#34;根据出生日期计算年龄\&#34;, \&#34;parameters\&#34;: {\&#34;type\&#34;: \&#34;object\&#34;, \&#34;properties\&#34;: {\&#34;birthdate\&#34;: {\&#34;type\&#34;: \&#34;string\&#34;, \&#34;description\&#34;: \&#34;出生日期以YYYY-MM-DD格式表示\&#34;}}, \&#34;required\&#34;: [\&#34;birthdate\&#34;]}}]&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h4 class="relative group">偏好数据集<div id=%E5%81%8F%E5%A5%BD%E6%95%B0%E6%8D%AE%E9%9B%86-1 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%81%8F%E5%A5%BD%E6%95%B0%E6%8D%AE%E9%9B%86-1 aria-label=锚点>#</a></span></h4><p>Sharegpt 格式的偏好数据集同样需要在 chosen 列中提供更优的消息，并在 rejected 列中提供更差的消息。 下面是一个例子：</p><h4 class="relative group">OpenAI 格式<div id=openai-%E6%A0%BC%E5%BC%8F class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#openai-%E6%A0%BC%E5%BC%8F aria-label=锚点>#</a></span></h4><p>OpenAI 格式仅仅是 sharegpt 格式的一种特殊情况，其中第一条消息可能是系统提示词。</p><h2 class="relative group">SFT 超参数调整：<div id=sft-%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#sft-%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4 aria-label=锚点>#</a></span></h2><p>比如 10 万个样本 2-3 个 epoch 内为佳，2 ～ 5 万个样本 一般是 4-5 个 epoch 并且领域增强的 SFT 数据不需要太多，质量一定要把握好，一般的领域总结回复的任务几百条数据即可（ 个人经验 ），视情况而定;小数据量可以适当增大 epoch，让模型充分收敛。</p><p>例如：EPOCH：100 条数据时, Epoch 为 15，1000 条数据时, Epoch 为 10，10000 条数据时, Epoch 为 2。</p><ul><li><strong>Epochs</strong>：需要根据数据集多少动态调整，比如 100 条数据时, Epoch 设置为 15，1000 条数据时, Epoch 为 10，10000 条数据时, Epoch 为 2。</li><li><strong>Learning Rate</strong>：根据不同微调方法 LR 也需要调整，对于 LoRA 的 peft 训练方式，同时可以适当增大 LR</li><li><strong>Global BatchSize</strong>：调整 bs 可以加快训练速度，但是也会增加显存占用，需要根据 GPU 资源调整。如增加 accumulate step 32 64，当分布式节点增多时可以进一步增加 batch_size，提高吞吐。</li></ul><h2 class="relative group">RLHF<div id=rlhf class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#rlhf aria-label=锚点>#</a></span></h2><p>RLHF 是一种训练方式，并不是类似 Lora 这种的训练方法，RLHF 可以分为三阶段：</p><ol><li><strong>Language Model，LM</strong>：一个预训练语言模型 LM，对基础模型微调得到一个微调后的模型<ul><li>使用人工标注的数据对预训练模型进行监督微调，以获得初始版本的生成模型。</li></ul></li><li><strong>Reward Model，RM</strong>：训练一个奖励模型 RM：训练一个奖励模型（Reward Model），用于评估生成模型的输出质量。<ul><li>收集生成模型输出及其对应的人类反馈。这些反馈可以是评分、选择最佳输出、直接修改等形式。</li><li>使用这些反馈数据训练奖励模型，使其能够对生成的输出进行评分。</li><li>奖励模型通常是一个监督学习模型，通过最小化预测评分与人类反馈评分之间的差距进行训练。</li></ul></li><li><strong>Reinforcement Learning，RL</strong>：用强化学习 RL 方式微调 LM ：使用强化学习算法（如 <strong>PPO（Proximal Policy Optimization）</strong>）进一步优化第一步中生成的模型，使其输出更符合人类反馈的期望。<ul><li>使用初始生成模型产生输出，并通过奖励模型评估这些输出的质量</li><li>使用 PPO 算法，根据奖励模型的评分更新生成模型的参数。<ul><li>PPO 是一种强化学习算法，旨在平衡探索和利用，通过限制每次更新的幅度，确保稳定性和效率。</li><li>算法优化生成模型的策略，使其输出在奖励模型的评分下不断提升。</li></ul></li><li>反复进行生成、评估、优化的循环，逐步提高生成模型的性能。</li></ul></li></ol><h2 class="relative group">DPO<div id=dpo class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#dpo aria-label=锚点>#</a></span></h2><p>RLHF 是一种复杂且通常不稳定的过程，首先需要拟合反映人类偏好的奖励模型，然后使用强化学习来微调无监督 LM 以最大化这一估计的奖励，同时避免与原始模型偏离过远。</p><p>**直接偏好优化（DPO）**是一种简单的无强化学习的语言模型偏好训练算法。</p><p><figure><img class="my-0 rounded-md" loading=lazy srcset="/docs/study/20250219_qwen_fine_tune/image/index/1739970909068_hu8808878782639583770.png 330w,
/docs/study/20250219_qwen_fine_tune/image/index/1739970909068_hu4805126212613325627.png 660w,
/docs/study/20250219_qwen_fine_tune/image/index/1739970909068_hu12604451269538783751.png 1024w,
/docs/study/20250219_qwen_fine_tune/image/index/1739970909068_hu8152279313523712309.png 2x" src=/docs/study/20250219_qwen_fine_tune/image/index/1739970909068_hu4805126212613325627.png alt=1739970909068></figure></p><h2 class="relative group">如何训练垂直领域大模型<div id=%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B aria-label=锚点>#</a></span></h2><p>因为 Chat 模型就是在 Base 模型基础上做了微调以适应对话任务，掌握了生成对话内容的能力的 SFT 模型，因此再对 Chat 模型做 SFT 触发 灾难性遗忘 风险就比较高，相比之下 Base 因为没经过微调，因为触发 灾难性遗忘 的风险会比较低。
因此选择哪种模型取决于我们的场景。</p><ul><li>青春版：Chat 模型 + SFT
资源消耗少、模型通用能力有所降低</li><li>完整版：Base 模型 + 增量预训练(Continue PreTraining) + SFT
资源消耗大、模型通用能力完整保留</li></ul><p><strong>最终一个完整的训练垂直领域大模型可以分为以下三步：</strong></p><ul><li><strong>Continue PreTraining(增量预训练)</strong> : 一般垂直大模型是基于通用基座大模型进行二次的训练，为了给模型注入领域知识，就需要用领域内的语料进行继续预训练。</li><li><strong>SFT ( Supervised Finetuning,有监督微调)</strong>: 通过 SFT 可以激发大模型理解领域内的各种问题并进行回答的能力(在有召回知识的基础上)</li><li><strong>强化学习</strong>：一般是二选一
RLHF(奖励建模、强化学习训练): 通过 RLHF 可以让大模型的回答对齐人们的偏好，比如行文的风格。
DPO(直接偏好优化)</li></ul><h1 class="relative group">微调实例<div id=%E5%BE%AE%E8%B0%83%E5%AE%9E%E4%BE%8B class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%BE%AE%E8%B0%83%E5%AE%9E%E4%BE%8B aria-label=锚点>#</a></span></h1><ol><li><p>服务器部署</p></li><li><p>环境配置
创建虚拟环境
安装 LLaMAFactory</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone -b v0.8.1 https://github.com/hiyouga/LLaMA-Factory.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> LLaMA-Factory
</span></span><span class=line><span class=cl>pip install -e .<span class=o>[</span>torch,metrics<span class=o>]</span>
</span></span></code></pre></div></li><li><p>准备模型
使用 Qwen2.5-7B-Instruct 模型进行微调</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl> <span class=c1># 安装并初始化 git-lfs</span>
</span></span><span class=line><span class=cl> apt install git-lfs -y
</span></span><span class=line><span class=cl> git lfs install
</span></span><span class=line><span class=cl> <span class=c1># 下载模型</span>
</span></span><span class=line><span class=cl> git lfs clone https: //www.modelscope.cn/qwen/Qwen2.5-7B-Instruct.git
</span></span></code></pre></div></li><li><p>准备数据集
在 LLaMA-Factory 中，数据集的格式是一个 json 文件，每一行是一个 json 对象，根据项目需求，创建一个 Alpaca 格式的数据集</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl> <span class=p>[</span>
</span></span><span class=line><span class=cl>     <span class=p>{</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;判断用户的情感倾向(正面/负面/中性)。&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;input&#34;</span>      <span class=p>:</span> <span class=s2>&#34;输入：地铁十号线真挤&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>         <span class=nt>&#34;output&#34;</span>     <span class=p>:</span> <span class=s2>&#34;负面。是对交通出行舒适度的评价。&#34;</span>
</span></span><span class=line><span class=cl>     <span class=p>}</span>
</span></span><span class=line><span class=cl> <span class=p>]</span>
</span></span></code></pre></div><p>将新增数据集注册到 <code>LLaMAFactory</code> 中：</p><ul><li>将数据集移动到 <code>data</code> 目录下</li><li>修改 <code>dataset_info.json</code> 注册数据集</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>root@test: /LLaMA-Factory# cat data/dataset_info.json
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;comments&#34;</span>: <span class=o>{</span>
</span></span><span class=line><span class=cl>     <span class=s2>&#34;file_name&#34;</span>: <span class=s2>&#34;comments.json&#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>,
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div></li><li><p>开始微调
新版提供了 llamafactory-cli 命令行工具使用。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl> <span class=nv>modelPath</span> <span class=o>=</span> models/Qwen1.5-1.8B-Chat
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> llamafactory-cli train <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --model_name_or_path <span class=nv>$modelPath</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stage sft <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --do_train <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --finetuning_type lora <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --template qwen <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dataset identity <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --output_dir ./saves/lora/sft <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --learning_rate 0.0005 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --num_train_epochs <span class=m>8</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --cutoff_len <span class=m>4096</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --logging_steps <span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --warmup_ratio 0.1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --weight_decay 0.1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --gradient_accumulation_steps <span class=m>8</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --save_total_limit <span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --save_steps <span class=m>256</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --seed <span class=m>42</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --data_seed <span class=m>42</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --lr_scheduler_type cosine <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --overwrite_cache <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --preprocessing_num_workers <span class=m>16</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --plot_loss <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --overwrite_output_dir <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --per_device_train_batch_size <span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --fp16
</span></span></code></pre></div></li></ol><h2 class="relative group">结果查看<div id=%E7%BB%93%E6%9E%9C%E6%9F%A5%E7%9C%8B class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E7%BB%93%E6%9E%9C%E6%9F%A5%E7%9C%8B aria-label=锚点>#</a></span></h2><p><strong>查看 LoRA 权重</strong>
根据日志可以看到，微调后的模型保存到了我们指定的 ./saves/lora/sft 目录</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>[</span>INFO<span class=p>|</span>trainer.py:3410<span class=o>]</span> 2025-02-19 20: 51: 37, <span class=m>168</span> &gt;&gt; Saving model checkpoint to ./saves/lora/sft
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>root@lixd-sft: /LLaMA-Factory# ll -lhS ./saves/lora/sft
</span></span></code></pre></div><p><strong>查看 loss 曲线</strong>
训练过程中会实时打印训练日志，其中就包括了 loss 信息，就像这样：</p><blockquote><p>微调参数 –logging_steps = 1 因为每一步都会打印日志</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39;loss&#39;</span>: 3.9236, <span class=s1>&#39;grad_norm&#39;</span>: 2.572678327560425, <span class=s1>&#39;learning_rate&#39;</span>: 8.333333333333333e-05, <span class=s1>&#39;epoch&#39;</span>: 0.09<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39;loss&#39;</span>: 3.3305, <span class=s1>&#39;grad_norm&#39;</span>: 1.8977322578430176, <span class=s1>&#39;learning_rate&#39;</span>: 0.00016666666666666666, <span class=s1>&#39;epoch&#39;</span>: 0.18<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39;loss&#39;</span>: 4.3762, <span class=s1>&#39;grad_norm&#39;</span>: 2.840055227279663, <span class=s1>&#39;learning_rate&#39;</span>: 0.00025, <span class=s1>&#39;epoch&#39;</span>: 0.26<span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>.....
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39;loss&#39;</span>: 0.1993, <span class=s1>&#39;grad_norm&#39;</span>: 0.9958950281143188, <span class=s1>&#39;learning_rate&#39;</span>: 2.052496544188487e-06, <span class=s1>&#39;epoch&#39;</span>: 4.66<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39;loss&#39;</span>: 0.407, <span class=s1>&#39;grad_norm&#39;</span>: 1.3202508687973022, <span class=s1>&#39;learning_rate&#39;</span>: 5.136518124159162e-07, <span class=s1>&#39;epoch&#39;</span>: 4.75<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39;loss&#39;</span>: 0.2622, <span class=s1>&#39;grad_norm&#39;</span>: 1.1825435161590576, <span class=s1>&#39;learning_rate&#39;</span>: 0.0, <span class=s1>&#39;epoch&#39;</span>: 4.84<span class=o>}</span>
</span></span></code></pre></div><p><figure><img class="my-0 rounded-md" loading=lazy srcset="/docs/study/20250219_qwen_fine_tune/image/index/1739972574555_hu8891200055559096661.png 330w,
/docs/study/20250219_qwen_fine_tune/image/index/1739972574555_hu17533636218651700012.png 660w,
/docs/study/20250219_qwen_fine_tune/image/index/1739972574555_hu4586486809265952477.png 1024w,
/docs/study/20250219_qwen_fine_tune/image/index/1739972574555_hu10534773545648418483.png 2x" src=/docs/study/20250219_qwen_fine_tune/image/index/1739972574555_hu17533636218651700012.png alt=1739972574555></figure><strong>成功的训练一般有明显的收敛过程</strong>，且收敛出现在训练过程的后半部分都是合理的。</p><ul><li>1）如果没有明显收敛，说明训练不充分，可以增加训练 epoch 重训，或者进行增量训练。</li><li>2）如果收敛出现在训练过程的前半部分，而后部分的 loss 平稳无变化，说明可能有过拟合，可以结合评估结果选择是否减少 epoch 重训。</li><li>3）如果有收敛趋势，但没有趋于平稳，可以在权衡通用能力和专业能力的前提下考虑是否增加 epoch 和数据以提升专业能力，但会有通用能力衰减的风险。
可以看到，在训练到 70 步再往后的时候已经收敛了，看起来本次训练效果还可以。</li></ul><h1 class="relative group">参考资料<div id=%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99 aria-label=锚点>#</a></span></h1><p><a href=https://www.lixueduan.com/posts/ai/04-finetune-concept/ target=_blank>大模型微调实战</a></p><pre tabindex=0><code></code></pre><pre tabindex=0><code></code></pre></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://api.qrserver.com/v1/create-qr-code/?data=https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/&amp;size=400x400&amp;color=000000&amp;bgcolor=FFFFFF&amp;margin=20&amp;qzone=5&amp;format=png" title aria-label><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 64C0 46.3 14.3 32 32 32c229.8.0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7.0 64zM128 416c0 35.3-28.7 64-64 64S0 451.3.0 416s28.7-64 64-64 64 28.7 64 64zM32 160c159.1.0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7.0-32-14.3-32-32s14.3-32 32-32z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/&amp;text=%e4%bd%bf%e7%94%a8%20LLaMAFactory%20%e5%ae%9e%e7%8e%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83" title="分享到 Twitter" aria-label="分享到 Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://t.me/share/url?url=https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/&amp;resubmit=true&amp;title=%e4%bd%bf%e7%94%a8%20LLaMAFactory%20%e5%ae%9e%e7%8e%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83" title aria-label><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M248 8C111.033 8 0 119.033.0 256S111.033 504 248 504 496 392.967 496 256 384.967 8 248 8zM362.952 176.66c-3.732 39.215-19.881 134.378-28.1 178.3-3.476 18.584-10.322 24.816-16.948 25.425-14.4 1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25 5.342-39.5 3.652-3.793 67.107-61.51 68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608 69.142-14.845 10.194-26.894 9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7 18.45-13.7 108.446-47.248 144.628-62.3c68.872-28.647 83.183-33.623 92.511-33.789 2.052-.034 6.639.474 9.61 2.885a10.452 10.452.0 013.53 6.716A43.765 43.765.0 01362.952 176.66z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://flesymeb.github.io/docs/study/20250219_qwen_fine_tune/&amp;subject=%e4%bd%bf%e7%94%a8%20LLaMAFactory%20%e5%ae%9e%e7%8e%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83" title=通过电子邮件发送 aria-label=通过电子邮件发送><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section><h2 class="mt-8 text-2xl font-extrabold mb-10">相关文章</h2><section class="w-full grid gap-4 sm:grid-cols-2 md:grid-cols-3"><a href=/posts/daily/2025-01-01/ class=min-w-full><div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative"><div class="w-full thumbnail_card_related nozoom" style=background-image:url(/img/MyImgs/lifeofpix/img16_hu12947621293233725824.jpg)></div><div class="px-6 py-4"><div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral" href=/posts/daily/2025-01-01/>2025 01 01</div><div class="text-sm text-neutral-500 dark:text-neutral-400"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-01-01T00:00:00+08:00>2025-01-01</time><span class="px-2 text-primary-500">&#183;</span><span>1635 字</span><span class="px-2 text-primary-500">&#183;</span><span title=预计阅读>4 分钟</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_posts/daily/2025-01-01/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></span></span></div><div class="flex flex-row flex-wrap items-center"></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/tags/%E6%AD%A5%E5%B1%A5%E4%B8%8D%E5%81%9C/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">步履不停
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/tags/%E6%97%A5%E5%B8%B8/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">日常
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/tags/25%23%E8%83%B6%E7%89%87/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">25#胶片</span></span></span></div></div></div><div class="px-6 pt-4 pb-2"></div></div></a></section></div><script>var oid="views_docs/Study/20250219_Qwen_Fine_Tune/index.md",oid_likes="likes_docs/Study/20250219_Qwen_Fine_Tune/index.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/docs/os/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">2024 操作系统期末复习</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-12-29T14:03:36+08:00>2024-12-29</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/docs/algorithm/stl/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">【算法】C++ STL的使用</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-05-19T19:20:08+08:00>2025-05-19</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label=返回顶部 title=返回顶部>&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/tags/ title>标签</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/authors/hyoungyan/ title>作者</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hyoung Yan</p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script><a rel=me href=https://flesymeb.github.io></a></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://flesymeb.github.io/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=搜索 tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="关闭 (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>